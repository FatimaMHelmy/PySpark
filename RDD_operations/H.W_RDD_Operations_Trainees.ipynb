{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07911b33",
   "metadata": {},
   "source": [
    "#### Application\n",
    "A user program built on Spark using its APIs. It consists of a driver program and executors on the cluster.\n",
    "\n",
    "#### SparkSession\n",
    "An object that provides a point of entry to interact with underlying Spark functionality and allows programming Spark with its APIs. In an interactive Spark shell, the Spark driver instantiates a SparkSession for you, while in a Spark application, you create a SparkSession object yourself.\n",
    "\n",
    "#### Job\n",
    "A parallel computation consisting of multiple tasks that gets spawned in response to a Spark action (e.g., save(), collect()).\n",
    "\n",
    "#### Stage\n",
    "Each job gets divided into smaller sets of tasks called stages that depend on each other.\n",
    "\n",
    "#### Task\n",
    "A single unit of work or execution that will be sent to a Spark executor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2568221b",
   "metadata": {},
   "source": [
    "### Import the required libraries then Create SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65e6978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install findspark\n",
    "# ! pip install numpy \n",
    "import findspark \n",
    "import numpy \n",
    "findspark.init()\n",
    "import pyspark\n",
    "from  pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b813bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08a25be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e958f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_instance = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88a1f799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-PLM8FHR:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x20ddd49c640>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48bbf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context = spark_instance.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7d9c6",
   "metadata": {},
   "source": [
    "### Create and display an RDD from the following list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "409084ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [('JK', 22), ('V', 24), ('Jimin',24), ('RM', 25), ('J-Hope', 25), ('Suga', 26), ('Jin', 27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9237653a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[11] at readRDDFromFile at PythonRDD.scala:287"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd0 = spark_context.parallelize(df)\n",
    "rdd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5ba0725",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JK', 22),\n",
       " ('V', 24),\n",
       " ('Jimin', 24),\n",
       " ('RM', 25),\n",
       " ('J-Hope', 25),\n",
       " ('Suga', 26),\n",
       " ('Jin', 27)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd0.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f82cf18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JK', 22), ('V', 24), ('Jimin', 24), ('RM', 25), ('J-Hope', 25)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd0.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823af0d6",
   "metadata": {},
   "source": [
    "### Create a sample1.txt file to contain the text shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4ce75e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample1.txt\", \"w\") as my_file:\n",
    "    my_file.write('''Utilitatis causa amicitia est quaesita.\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
    "Collatio igitur ista tenihil iuvat.\n",
    "Honesta oratio, Socratica, Platonis etiam. \n",
    "Primum in nostranepotestate est, quid meminerimus? \n",
    "Duo Reges: constructio interrete.\n",
    "Quid, sietiam iucunda memoria est praeteritorum malorum?\n",
    "Si quidem, inquit, tollerem,''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49249054",
   "metadata": {},
   "source": [
    "### Read sample1.txt file into RDD and displaying the first 4 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0732dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distfile = spark_context.textFile(\"sample1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "296da450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Utilitatis causa amicitia est quaesita.',\n",
       " 'Lorem ipsum dolor sit amet, consectetur adipiscing elit. ',\n",
       " 'Collatio igitur ista tenihil iuvat.',\n",
       " 'Honesta oratio, Socratica, Platonis etiam. ']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distfile.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0194c12",
   "metadata": {},
   "source": [
    "### Count the total number of rows in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "09f9d486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rdd_1 = distfile.map(lambda x: 1  )\n",
    "len(distfile.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4dc87",
   "metadata": {},
   "source": [
    "### Create a function to convert the data into lower case and splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e936fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['utilitatis', 'causa', 'amicitia', 'est', 'quaesita.'],\n",
       " ['lorem',\n",
       "  'ipsum',\n",
       "  'dolor',\n",
       "  'sit',\n",
       "  'amet,',\n",
       "  'consectetur',\n",
       "  'adipiscing',\n",
       "  'elit.'],\n",
       " ['collatio', 'igitur', 'ista', 'tenihil', 'iuvat.'],\n",
       " ['honesta', 'oratio,', 'socratica,', 'platonis', 'etiam.'],\n",
       " ['primum', 'in', 'nostranepotestate', 'est,', 'quid', 'meminerimus?'],\n",
       " ['duo', 'reges:', 'constructio', 'interrete.'],\n",
       " ['quid,',\n",
       "  'sietiam',\n",
       "  'iucunda',\n",
       "  'memoria',\n",
       "  'est',\n",
       "  'praeteritorum',\n",
       "  'malorum?'],\n",
       " ['si', 'quidem,', 'inquit,', 'tollerem,']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_split = distfile.map( lambda x:x.lower().split()  )\n",
    "rdd_split.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a9710f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_split.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437d37f",
   "metadata": {},
   "source": [
    "### Remove the stopwords from the previous text. i.e. Remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "358d6cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a','all','the','as','is','am','an','and',\n",
    "             'be','been','from','had','I','Iâ€™d','why','with']\n",
    "# Hint: you may need use flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a03bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split_remove = rdd_split.flatMap(lambda x: list(filter (lambda y :y not in stopwords ,x)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ffadc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['utilitatis',\n",
       " 'causa',\n",
       " 'amicitia',\n",
       " 'est',\n",
       " 'quaesita.',\n",
       " 'lorem',\n",
       " 'ipsum',\n",
       " 'dolor',\n",
       " 'sit',\n",
       " 'amet,',\n",
       " 'consectetur',\n",
       " 'adipiscing',\n",
       " 'elit.',\n",
       " 'collatio',\n",
       " 'igitur',\n",
       " 'ista',\n",
       " 'tenihil',\n",
       " 'iuvat.',\n",
       " 'honesta',\n",
       " 'oratio,',\n",
       " 'socratica,',\n",
       " 'platonis',\n",
       " 'etiam.',\n",
       " 'primum',\n",
       " 'in',\n",
       " 'nostranepotestate',\n",
       " 'est,',\n",
       " 'quid',\n",
       " 'meminerimus?',\n",
       " 'duo',\n",
       " 'reges:',\n",
       " 'constructio',\n",
       " 'interrete.',\n",
       " 'quid,',\n",
       " 'sietiam',\n",
       " 'iucunda',\n",
       " 'memoria',\n",
       " 'est',\n",
       " 'praeteritorum',\n",
       " 'malorum?',\n",
       " 'si',\n",
       " 'quidem,',\n",
       " 'inquit,',\n",
       " 'tollerem,']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_split_remove.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f6058",
   "metadata": {},
   "source": [
    "### Find the words starting with â€˜câ€™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b46050",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split.collect()\n",
    "rdd_split.saveAsTextFile('rdd_split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4512cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['utilitatis', 'causa', 'amicitia', 'est', 'quaesita.'],\n",
    " ['lorem',\n",
    "  'ipsum',\n",
    "  'dolor',\n",
    "  'sit',\n",
    "  'amet,',\n",
    "  'consectetur',\n",
    "  'adipiscing',\n",
    "  'elit.'],\n",
    " ['collatio', 'igitur', 'ista', 'tenihil', 'iuvat.'],\n",
    " ['honesta', 'oratio,', 'socratica,', 'platonis', 'etiam.'],\n",
    " ['primum', 'in', 'nostranepotestate', 'est,', 'quid', 'meminerimus?'],\n",
    " ['duo', 'reges:', 'constructio', 'interrete.'],\n",
    " ['quid,',\n",
    "  'sietiam',\n",
    "  'iucunda',\n",
    "  'memoria',\n",
    "  'est',\n",
    "  'praeteritorum',\n",
    "  'malorum?'],\n",
    " ['si', 'quidem,', 'inquit,', 'tollerem,']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eeacae3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e1f61c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split_c = spark_context.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10847256",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split_c = rdd_split_c.flatMap(lambda x: list(filter (lambda y :y.startswith(\"c\"),x)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "224c680a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['causa', 'consectetur', 'collatio', 'constructio']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_split_c.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba39e2e",
   "metadata": {},
   "source": [
    "### Reduce the data by key and sum it (use the data from the following list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f26dea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [('JK', 22), ('V', 24), ('Jimin',24), ('RM', 25)\n",
    "        , ('J-Hope', 25), ('Suga', 26), ('Jin', 27)\n",
    "       , ('J-Hope', 12), ('Suga', 25), ('Jin', 34)\n",
    "       , ('JK', 32), ('V', 44), ('Jimin',14), ('RM', 35)]\n",
    "# Hint: use reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "134eb011",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_key = spark_context.parallelize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0dd34e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_key_grouped = rdd_key.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b034d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JK', <pyspark.resultiterable.ResultIterable at 0x20ddd938d00>),\n",
       " ('J-Hope', <pyspark.resultiterable.ResultIterable at 0x20ddd938c10>),\n",
       " ('Suga', <pyspark.resultiterable.ResultIterable at 0x20ddd938820>),\n",
       " ('Jin', <pyspark.resultiterable.ResultIterable at 0x20ddd938760>),\n",
       " ('V', <pyspark.resultiterable.ResultIterable at 0x20ddd938280>),\n",
       " ('Jimin', <pyspark.resultiterable.ResultIterable at 0x20ddd938730>),\n",
       " ('RM', <pyspark.resultiterable.ResultIterable at 0x20ddd9388e0>)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_key_grouped.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae551b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JK', [22, 32]),\n",
       " ('J-Hope', [25, 12]),\n",
       " ('Suga', [26, 25]),\n",
       " ('Jin', [27, 34]),\n",
       " ('V', [24, 44]),\n",
       " ('Jimin', [24, 14]),\n",
       " ('RM', [25, 35])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = rdd_key_grouped.collect()\n",
    "results = [ (k,list(v)) for  (k,v) in results ]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05e52a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JK', 54),\n",
       " ('J-Hope', 37),\n",
       " ('Suga', 51),\n",
       " ('Jin', 61),\n",
       " ('V', 68),\n",
       " ('Jimin', 38),\n",
       " ('RM', 60)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_key_grouped_sum = rdd_key_grouped.map(lambda x : (x[0],sum (x[-1])))\n",
    "rdd_key_grouped_sum.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4587230",
   "metadata": {},
   "source": [
    "### Creat some key value pairs RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfb446ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = spark_context.parallelize([('a',2),('b',3)])\n",
    "rdd2 = spark_context.parallelize([('a',9),('b',7),('c',10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5621bdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 9), ('b', 7), ('c', 10)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e4ef9f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 2), ('b', 3)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec3168",
   "metadata": {},
   "source": [
    "### Perform Join operation on the RDDs (rdd1,rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fc98e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', (2, 9)), ('b', (3, 7))]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.join(rdd2).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
